# Blink-and-Snap
This project was created to meet the requirements of our interdisciplinary project by Physics (Sahir Nagpal and Oliver Ashton) and Data Science students (Kathy Huang and Johnson Yun). In this project, we attempt to make an eye controlled camera to allow additional degrees of freedom to camera users as well as the physically disabled.

The key skills used in the project are signal processing, signal classifying, live streaming and camera integration.

The files contain the following information - 

1) Blink and Snap (Group11) - Final Code.ipynb
* The code is used to process and classify the signal as an event as well as bind the classified events to the camera to perform actions whilst live streaming.
2) Group 11 Prerecorded Demo.mp4
* Contains a recording of the camera in action
3) Project_Detailed_Report.pdf
* Containes all the details regarding the project
4) Sample File Bandpass.wav
* This is a recorded signal used to explain events in the final report after being passed through a bandpass filter to remove all the high frequency noise.
5) Sample File Raw.wav
* This is a recorded signal used to explain events in the final report
6) Wave Analysis.ipynb
* This code provieds a thorough analysis of the wave (signal) and different methods tried on the signal to obtain the best accuracy
7) Working Camera.ipynb
* This file contains the code used to access the camera and perform actions such as zzoming in or clicking the image.
